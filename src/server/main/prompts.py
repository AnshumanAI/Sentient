# src/server/main/prompts.py
# This file will store prompts for LLM interactions.
# For now, with dummy responses, it might be empty or have placeholder comments.

# Example (if used for constructing dummy responses or system prompts):
# DUMMY_CHAT_SYSTEM_PROMPT = "You are a helpful, but very simple, assistant."